Multimodal interaction (\textit{e.g.}, combining speech and pointing) can reduce cognitive load for complex tasks and make tedious tasks more efficient, by enabling users to interact more naturally with systems and spread their load across multiple senses []. 

COMING UP WITH SEARCH IN THE FIRST PLACE: Multimodal (from UIST demo)
Multimodal interaction can reduce cognitive load for complex tasks and make tedious tasks more efficient [?]. Different types of information lend themselves better to different modalities; leveraging the strengths of multiple modalities and integrating them smoothly can be extremely effective [7]. For example, combining speech and pointing allows people to communicate more precisely and efficiently by using deictic terms (e.g., “this”, “here”) to refer to objects and locations [1, 6]. Furthermore, using multiple modalities simultaneously can improve efficiency for tedious or involved tasks; e.g., navigating tutorial videos with speech while one’s hands are busy with a physical task [2], or using a voice assistant to set reminders on the go. Finally, multimodal systems can also enable more natural interaction; e.g., letting users describe photo edits in their own words and inferring the appropriate commands [6], or activating software commands with speech rather than memorizing keyboard shortcuts [5].
