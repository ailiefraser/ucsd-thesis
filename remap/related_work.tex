Multimodal interaction (\textit{e.g.}, combining speech and pointing) can reduce cognitive load for complex tasks and make tedious tasks more efficient, by enabling users to interact more naturally with systems and spread their load across multiple senses []. 

COMING UP WITH SEARCH IN THE FIRST PLACE: Multimodal (from UIST demo)
Multimodal interaction can reduce cognitive load for complex tasks and make tedious tasks more efficient [?]. Different types of information lend themselves better to different modalities; leveraging the strengths of multiple modalities and integrating them smoothly can be extremely effective [7]. For example, combining speech and pointing allows people to communicate more precisely and efficiently by using deictic terms (e.g., “this”, “here”) to refer to objects and locations [1, 6]. Furthermore, using multiple modalities simultaneously can improve efficiency for tedious or involved tasks; e.g., navigating tutorial videos with speech while one’s hands are busy with a physical task [2], or using a voice assistant to set reminders on the go. Finally, multimodal systems can also enable more natural interaction; e.g., letting users describe photo edits in their own words and inferring the appropriate commands [6], or activating software commands with speech rather than memorizing keyboard shortcuts [5].

include square to describe multimodal work

visual                     verbal/linguistic
motor/manual       mouth/spoken

remap uses all 4 of these \^ and partitions them between tasks in a clever way
get to keep not just your hands where they are but also your EYES


* pixeltone finding: Speech was preferred more when users knew what they wanted to do, preferred gallery mode when they weren’t sure what to do -- noted that seeing the visual previews in gallery mode was helpful while this wasn’t available with speech
    * replay is most useful when people have a targeted question, so this is a good application for multimodal as that is also when speech is useful
    
    
Multimodal prior work to look at:
* https://blairmacintyre.me/publications/
* Manu Kumar’s thesis / phd work - maybe this video has something? https://www.youtube.com/watch?v=7-OmM31MvBw
* midas touch problem origin https://dl.acm.org/citation.cfm?id=97246