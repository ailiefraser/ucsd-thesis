\section{Discussion / Challenges}
\subsection{Implementation Challenges}
- having to be a macos app because accessibility, but no good speech so having to use web speech api
- accessibility in general not super good --> deictic failed a lot
\subsection{Usability Challenges}
- searching unintentionally (midas touch)
- or not listening when keyword was misheard
- cutting off before they were done talking
- correcting query is hard, mostly resort to typing or people would repeat themselves but system isn't that smart
- showing query as they spoke might have been distracting - they weren't looking at the task anymore
\subsection{Potentail IMprovements / future exploration to do}
- compare keyword to search vs. button / keyboard shortcut
- let user decide when done talking (adds extra step but could prevent errors)
- explore how to correct queries (existing work?) using speech -- detect if they repeat themselves and go with the second version, or suport things like "x instead of y"
- compare not showing query (just listening) vs. showing it
- other ways to do deictic -- computer vision like prefab?
- higher level -- do people really want deictic? is it useful? most queries (as we found with replay too) were not about tools so being able to refer to them isn't that useful, and other things (like objects on the canvas) people mostly know what they are called so it doesn't save much time
- deictic may be more useful for issuing commands or sending questions to people / posting in forums




A long-term goal of ours is allowing for RePlay to process search queries independently aside from in accordance with a working application. A user may want to search for how to complete a task but not know which application is the best to do so—for example converting an image to JPEG. The menu bar will have the setting, but a user might not know which software application to use or where to look. In our proposed system, a user might search or verbalize “How do I convert an image to JPEG?” RePlay would leverage the user’s application context and history to search for options. The most-used application, for example, is Photoshop, so RePlay would play the relevant video clips relating to Photoshop that address the search. Below the video is a button, “Tell Me More,” that reveals the full RePlay interface. 




How to make a naturally spoken query into an effective search query
Come up with algorithm for transforming query from natural speech into a good search query
Remove unnecessary words like um and so
Recognize when user is repeating themself and shorten
Recognize synonyms for app-specific terminology and automatically change to the correct terminology 
Add additional terms from user context when appropriate




Doing deictic stuff at a higher level - i.e. understanding semantic meaning of things being pointed to rather than just tool names

Search and watch videos on phone instead of taking up desktop screen real estate
