\section{Related Work}
%YouTube also contains many videos that specifically address cross-app workflows (e.g., exporting content from one application and importing it into another). 
This work builds on prior contextual search and video segmentation work with a novel focus on multi-application activities.
%This necessitates an application-general approach for detecting context and a domain-general approach for searching and ranking. 

\subsection{Multi-application Activities are Hard to Support Consistently}
People often work across multiple applications that each support an individual task to perform higher-level activities \cite{Sumner1997}. Help systems for such applications tend to focus on their individual tasks rather than the transitions and interactions between applications \cite{Norman2005}. Implementing system-wide assistance that captures activity context is difficult, as every application has its own conventions and interface, and software interoperability tends to be limited \cite{Beaudouin-Lafon2018}. Accessibility \textsc{api}s are one useful entry point for diverse system-wide extensibility, including visualizing user behavior \cite{Matejka2013}, voice control \cite{Li2017, Zhong2014}, and modifying or enhancing existing user interfaces \cite{Dixon2014, Stuerzlinger2006, Chang2011}.
RePlay uses accessibility \textsc{api}s for detecting system-wide application context.
% one inspiration for this work is the emergence of creative professionals live streaming their work. these live streams offer a more holistic view than ``help'' because viewers can see how specific functions fit together. 

\subsection{Application Context Improves Relevance and Presentation of Help Resources}
% The most teachable moment for software tasks is often when the user is actively working... but stuck. In-task help for a specific goal is one of the biggest reasons people seek web \cite{Lafreniere2013a} and video \cite{AlamAnik2015} tutorials. However, tutorials tend to show a full task from start to finish, much of which may not be relevant to the user's current goal. This leaves it to the user to both find a relevant tutorial and locate the segment(s) within it that contains the needed information.

Effectively searching the Web for help is an acquired skill; coming up with the right keywords and search settings can be difficult, especially for novices \cite{Russell2011}. In addition, web search environments lack context that human tutors use to proactively offer help and tailor feedback \cite{Schon1983}. Adding contextual terms automatically to search queries (\textit{e.g.,} \textsc{os} version, application, recently-used tools) can help improve the relevance and utility of search results without requiring the user to know app-specific terminology \cite{Ekstrand2011, Brandt2010, Matejka2011a}. RePlay augments queries with the current application name and uses context from both the current and recently-used applications to support cross-application activities when ranking search results.

Adding contextual cues to search results provides information scent that can help users more quickly and easily navigate the results (\autoref{fig:replay-green_markers}). Such cues show how and why a result is relevant to the user's own situation and direct them to the relevant information within a result \cite{Ekstrand2011, Fourney2014Intertwine}. RePlay expands these ideas to video, displaying contextual cues for recently-used applications and tools.

% Bringing learning resources directly into applications reduces the need for context switching. For example, proactively recommending content in-situ based on user context can lead users to resources they might not have even thought to search for \cite{Matejka2009, Fraser2016, Chilana2012, Matejka2011, Ichinco2017}. In-app search also helps users stay focused on their task while learning \cite{Lafreniere2014a, Fraser2016, Chilana2012}. RePlay brings these strategies into an application-independent system, functioning alongside the user's applications.

\subsection{Videos are Popular for Learning but Hard to Search and Browse}
% Videos are popular for many kinds of tasks, especially visual ones, because they show clear demonstrations that might be harder to explain or understand in text \cite{Chi2012, Pongnumkul2011}. 
Videos are widely available and relatively easy to make. Software is always being updated, and new video demonstrations are constantly added to popular platforms by the user community to keep up with updates and current trends. 
However, not only is navigating within a \textit{single} video difficult and tedious \cite{Pavel2014, Pavel2015, Kim2014}, finding the right video in a list of search results can be even harder.
%However, while text-based documents are easy to skim and search, videos are not \cite{Pavel2014, Pavel2015, Kim2014}.
The predominant video search approach displays results as thumbnail images with a title and summary (\textit{e.g.,} YouTube, Vimeo). This presentation only provides a broad overview without cues about matching content; prior work has shown that people look for indications of how search results are relevant to their query \cite{Hearst2009Book}. 
%Navigating within videos is typically limited to hovering across the timeline with a small visual preview.

Like some prior work \cite{Pavel2014, Pavel2015, Girgensohn2005}, RePlay uses captions to select relevant clips from online videos. Automatic clip selection plays a limited but growing role in web search. Google displays a ``suggested video clip'' \cite{Sullivan2018} as the automated summary for some searches, and Bing's ``smart motion preview'' feature \cite{Bing} shows a 30-second preview for video search results. In contrast, RePlay focuses on searching with and presenting results within application context. Chi \textit{et al.} \cite{Chi2012} showed people benefit most from a mix of text and video; RePlay combines video and text instruction by presenting captions with videos for both navigational and learning assistance.

%Methods for navigating between video segments include interactive timeline markers \cite{Matejka2011, Grossman2010, Kim2014, Banovic2012, Kim2014a}, thumbnail images \cite{Kim2014a, Pongnumkul2011, Banovic2012, Grossman2010a, Chi2012, Pavel2014}, transcript text \cite{Kim2014a}, and clickable elements overlaid on the video \cite{Nguyen2015}.
Like Ambient Help \cite{Matejka2011}, ToolScape \cite{Kim2014}, and Chronicle \cite{Grossman2010}, RePlay overlays markers on the timeline indicating tool use. We use timeline markers over other types of annotations as they take up little space and allow for pop-up text previews, which aid browsing. While prior work marks \textit{all} instances of tool use and command execution, RePlay marks only \textit{contextually-relevant} moments (recently-used tools and words from the user's query) to reduce clutter and unnecessary detail in a small interface.


%As a result, the learning materials online differ for each application as well. Different keywords may be necessary to find help for a given task depending what application you are using for that task.
%But maybe we don't need application-specific knowledge. Maybe we can just make use of existing system-wide functionality, get the minimum information it provides for most applications, and use that to augment existing search engines just enough to support these activities a little better.

%This requires the user to translate their own context and situation back and forth with that in the browser. Users must determine what of their context might potentially be relevant and articulate a search query appropriately, determine which search results might be relevant to this context based on their information scent, and finally map the instructions received back to their own unique situation. (maybe move to a separate section?)